import time
import streamlit as st
import pandas as pd
from sql_utils import get_sql_connection, execute_sql_query
from spark_utils import get_spark_session, execute_spark_query

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="SQL vs Spark Benchmark", layout="wide")
st.title("üöÄ Comparaci√≥n de Rendimiento: SQL Server vs Spark")

# Sidebar - Configuraci√≥n de conexi√≥n
st.sidebar.header("üîß Configuraci√≥n de Conexi√≥n")
server = st.sidebar.text_input("Servidor SQL", "192.168.5.136")
database = st.sidebar.text_input("Base de datos", "ReferenciasComerciales")
username = st.sidebar.text_input("Usuario", "Adrian.Araya")
password = st.sidebar.text_input("Contrase√±a", "Soporte1990%", type="password")

# Consulta SQL de ejemplo
default_query = """SELECT TOP (100000) 
      [Identificacion],
      [Nombre]
FROM [ReferenciasComerciales].[dbo].[ReferenciasCCSS]"""

query = st.text_area("üìù Consulta SQL", default_query, height=150)

# Opci√≥n para habilitar/deshabilitar Spark
use_spark = st.sidebar.checkbox("Habilitar comparaci√≥n con Spark", value=True)

# Secci√≥n de ejecuci√≥n
if st.button("‚ö° Ejecutar Comparaci√≥n", type="primary"):
    if not query:
        st.error("‚ö†Ô∏è Por favor ingrese una consulta SQL v√°lida")
    
    else:
        # Contenedores para resultados
        sql_col, spark_col = st.columns(2)
        
        try:
            # Conexi√≥n y ejecuci√≥n SQL
            with sql_col:
                st.subheader("üîµ SQL Server")
                with st.spinner("Conectando a SQL Server..."):
                    conn = get_sql_connection(server=server, database=database, username=username, password=password)
                
                with st.spinner("Ejecutando consulta SQL..."):
                    sql_df, sql_time = execute_sql_query(conn, query)
                
                st.success(f"‚úÖ Tiempo SQL: {sql_time:.2f} segundos")
                st.metric("Registros recuperados", f"{len(sql_df):,}")
                
                # Mostrar resultados
                st.dataframe(sql_df.head(), use_container_width=True)
                
                # Opci√≥n para descargar resultados
                csv = sql_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "üì§ Descargar resultados SQL",
                    csv,
                    "resultados_sql.csv",
                    "text/csv"
                )
            
            # Conexi√≥n y ejecuci√≥n Spark (si est√° habilitado)
            if use_spark:
                with spark_col:
                    st.subheader("üü† Apache Spark")
                    with st.spinner("Inicializando Spark..."):
                        spark = get_spark_session()
                    
                    with st.spinner("Ejecutando consulta en Spark..."):
                        spark_df, spark_time = execute_spark_query(spark, server="192.168.5.136", port="18698", database="ReferenciasComerciales", 
                                                                   username="Adrian.Araya", password="Soporte1990%", query=query)
                    
                    st.success(f"‚úÖ Tiempo Spark: {spark_time:.2f} segundos")
                    st.metric("Registros procesados", f"{spark_df.count():,}")
                    
                    # Mostrar resultados
                    st.dataframe(spark_df.limit(5).toPandas(), use_container_width=True)
            
            # Secci√≥n de comparaci√≥n
            st.subheader("üìä Comparaci√≥n de Rendimiento")
            
            if use_spark:
                comparison_data = {
                    'Sistema': ['SQL Server', 'Apache Spark'],
                    'Tiempo (segundos)': [sql_time, spark_time],
                    'Registros': [len(sql_df), spark_df.count()]
                }
                
                col1, col2 = st.columns(2)
                with col1:
                    st.bar_chart(data=comparison_data, x='Sistema', y='Tiempo (segundos)')
                with col2:
                    st.write(pd.DataFrame(comparison_data))
                
                ratio = sql_time / spark_time
                st.metric(
                    "Relaci√≥n de rendimiento (Spark/SQL)", 
                    f"{ratio:.2f}x m√°s {'r√°pido' if ratio > 1 else 'lento'}"
                )
            else:
                st.info("Comparaci√≥n con Spark deshabilitada en la configuraci√≥n")
        
        except Exception as e:
            st.error(f"‚ùå Error durante la ejecuci√≥n: {str(e)}")
            st.exception(e)
        
        finally:
            # Limpieza de recursos
            if 'conn' in locals():
                conn.close()
            if use_spark and 'spark' in locals():
                spark.stop()
                st.cache_resource.clear()

# Secci√≥n informativa
st.sidebar.markdown("""
### ‚ÑπÔ∏è Informaci√≥n
Esta aplicaci√≥n compara el rendimiento de:
- **SQL Server**: Ejecuci√≥n directa de consultas
- **Apache Spark**: Procesamiento distribuido

**Configuraci√≥n recomendada:**
- Servidor: `localhost` o nombre del contenedor SQL
- Base de datos: `performance_db` (creada autom√°ticamente)
""")

# Notas adicionales
st.markdown("""
---
### üìù Notas:
1. La primera conexi√≥n puede ser m√°s lenta debido a la inicializaci√≥n
2. Para consultas complejas, Spark puede mostrar mejor rendimiento
3. Los tiempos incluyen transferencia de datos
""")